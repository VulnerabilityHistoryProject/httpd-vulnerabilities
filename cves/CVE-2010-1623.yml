CVE: CVE-2010-1623

nickname_instructions: |
  Nickname is optional. Provide a useful, professional, and catchy nickname for
  this vulnerability. Ideally fewer than 30 characters. This will be shown
  alongside its CVE to make it more easily distinguished from the rest.
nickname: Lingering Timeout

CWE_instructions: |
  Please go to cwe.mitre.org and find the most specific, appropriate CWE entry
  that describes your vulnerability. (Tip: this may not be a good one to start
  with - spend time understanding this vulnerability before making your choice!)
CWE: 119

curated_instructions: |
  If you are manually editing this file, then you are "curating" it. Set the
  entry below to "true" as soon as you start. This will enable additional
  integrity checks on this file to make sure you fill everything out properly.
  If you are a student, we cannot accept your work as finished unless curated is
  set to true.
curated: true
announced_instructions: |
  Was there a date that this vulnerability was announced to the world? You can
  find this in changelogs, blogs, bug reports, or perhaps the CVE date. A good
  source for this is Chrome's Stable Release Channel
  (https://chromereleases.googleblog.com/).
  Please enter your date in YYYY-MM-DD format.
announced: 2010-10-04T21:00Z

description_instructions: |
  You can get an initial description from the CVE entry on cve.mitre.org. These
  descriptions are a fine start, but they can be kind of jargony.

  Rewrite this description in your own words. Make it interesting and easy to
  read to anyone with some programming experience. We can always pull up the NVD
  description later to get more technical.

  Try to still be specific in your description, but remove Chromium-specific
  stuff. Remove references to versions, specific filenames, and other jargon
  that outsiders to Chromium would not understand. Technology like "regular
  expressions" is fine, and security phrases like "invalid write" are fine to
  keep too.
description: |
  When HTTPD processes non-SSL (unencrypted) traffic, the way they process that
  data was flawed that allowed for memory to fill up. With carefully timed
  packets, an attacker could make the HTTPD process fill up on memory and cause
  a denial of service. The logic has to do with how timeout policies are
  enforced across core multiple modules in HTTPD.

  The subsystem, mod_reqtimeout, is designed to be "a convenient way to set
  timeouts and minimum data rates for receiving requests. Should a timeout occur
  or a data rate be to low, the corresponding connection will be closed by the
  server" (from https://httpd.apache.org/docs/trunk/mod/mod_reqtimeout.html).
  It is a filtering module, which works with HTTPD's "bucket brigade" model of
  accepting and parsing network data into the HTTPD quickly.

  In this vulnerability, the policy was loose by allowing 30 seconds to "linger"
  when a connection was scheduled for closing. This gives ample time for
  attackers to send crafted packets and fill up RAM. Instead, the policy was
  changed to 2 seconds, along with a big rewrite of how the policies are
  enforced.

bounty_instructions: |
  If you came across any indications that a bounty was paid out for this
  vulnerability, fill it out here. Or correct it if the information already here
  was wrong. Otherwise, leave it blank.
bounty:
  amt:
  announced:
  url:
reviews: []
bugs: []
repo:
fixes_vcc_instructions: |
  Please put the commit hash in "commit" below (see my example in
  CVE-2011-3092.yml). Fixes and VCCs follow the same format.
fixes:
   - commit: 970eadfab2f1a3c912c5f561f284221e487d832a
     note: Just a CHANGELOG change
   - commit: 15109e4e5f13314c97dc040aa96ef6ad7770f9e3
     note: This fix involved a significant rewrite of the functionality.
   - commit: ca1a8f6a297b7875d53393d0e8e7de1627bf0f9b
     note:
   - commit: c022637bd8328a7fc9019bf252b30f60db0d2303
     note:
   - commit: ceadbb2ba891b0822f5f6a493a80e4adda23431d
     note:
vccs:
  - commit: ed10ef0f7f93cba9f05887f0343895a2cd05964e
    note:
  - commit:
    note:
upvotes_instructions: |
  For the first round, ignore this upvotes number.

  For the second round of reviewing, you will be giving a certain amount of
  upvotes to each vulnerability you see. Your peers will tell you how
  interesting they think this vulnerability is, and you'll add that to the
  upvotes score on your branch.
upvotes: 10

unit_tested:
  question: |
    Were automated unit tests involved in this vulnerability?
    Was the original code unit tested, or not unit tested? Did the fix involve
    improving the automated tests?

    For the "code" answer below, look not only at the fix but the surrounding
    code near the fix and determine if and was there were unit tests involved
    for this module.

    For the "fix" answer below, check if the fix for the vulnerability involves
    adding or improving an automated test to ensure this doesn't happen again.
  answer: |
    No unit tests were changed for this fix, and no tests were found for this part
    of the system in the source tree.
  code: false
  fix: false

discovered:
  question: |
    How was this vulnerability discovered?

    Go to the bug report and read the conversation to find out how this was
    originally found. Answer in longform below in "answer", fill in the date in
    YYYY-MM-DD, and then determine if the vulnerability was found by a Google
    employee (you can tell from their email address). If it's clear that the
    vulenrability was discovered by a contest, fill in the name there.

    The "automated" flag can be true, false, or nil.
    The "google" flag can be true, false, or nil.

    If there is no evidence as to how this vulnerability was found, then you may
    leave this part blank.
  answer: |
    No evidence on how this vulnerability was originally reported. Fix just appears
  date:
  automated: false
  google: false
  contest:

subsystem:
  question: |
    What subsystems was the mistake in?

    Look at the path of the source code files code that were fixed to get
    directory names. Look at comments in the code. Look at the bug reports how
    the bug report was tagged.
  answer: Based on their commit messages
  name:
    - mod_reqtimeout
    - core

interesting_commits:
  question: |
    Are there any interesting commits between your VCC(s) and fix(es)?

    Write a brief (under 100 words) description of why you think this commit was
    interesting in light of the lessons learned from this vulnerability. Any
    emerging themes?
  commits:
    - commit:
      note:
    - commit:
      note:

major_events:
  question: |
    Please record any major events you found in the history of this
    vulnerability. Was the code rewritten at some point? Was a nearby subsystem
    changed? Did the team change?

    The event doesn't need to be directly related to this vulnerability, rather,
    we want to capture what the development team was dealing with at the time.
  answer:
  events:
    - name:
      date:
    - name:
      date:

lessons:
  question: |
    Are there any common lessons we have learned from class that apply to this
    vulnerability? In other words, could this vulnerability serve as an example
    of one of those lessons?

    Leave "applies" blank or put false if you did not see that lesson (you do
    not need to put a reason). Put "true" if you feel the lesson applies and put
    a quick explanation of how it applies.

    Don't feel the need to claim that ALL of these apply, but it's pretty likely
    that one or two of them apply.

    If you think of another lesson we covered in class that applies here, feel
    free to give it a small name and add one in the same format as these.
  defense_in_depth:
    applies:
    note:
  least_privilege:
    applies:
    note:
  frameworks_are_optional:
    applies:
    note:
  native_wrappers:
    applies:
    note:
  distrust_input:
    applies:
    note:
  security_by_obscurity:
    applies:
    note:
  serial_killer:
    applies:
    note:
  environment_variables:
    applies:
    note:
  secure_by_default:
    applies: true
    note: The fix for this vulnerability was about changing a timing policy, which is essentially hardcoded into the system.
  yagni:
    applies:
    note:
  complex_inputs:
    applies:
    note:

mistakes:
  question: |
    In your opinion, after all of this research, what mistakes were made that
    led to this vulnerability? Coding mistakes? Design mistakes?
    Maintainability? Requirements? Miscommunications?

    Look at the CWE entry for this vulnerability and examine the mitigations
    they have written there. Are they doing those? Does the fix look proper?

    Use those questions to inspire your answer. Don't feel obligated to answer
    every one. Write a thoughtful entry here that those ing the software
    engineering industry would find interesting.
  answer: |
    The fix to this vulnerability was a signifiant rewrite of the original
    functionality. The issue was not a small coding mistake, but a poor algorithm
    choice and poor defaults. More integration testing would have helped with this,
    especially with a memory management tool like Valgrind.
